{"cells":[{"cell_type":"markdown","metadata":{"id":"sj4Iane5AZ8q"},"source":["# RoBERTa using PyTorch\n"]},{"cell_type":"markdown","metadata":{"id":"qc5bHrkFAZ8t"},"source":["# All the important imports"]},{"cell_type":"code","source":["!pip install utils"],"metadata":{"id":"wF_Em5R0AvBY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709949036823,"user_tz":-480,"elapsed":12596,"user":{"displayName":"CHIANG KHENG HE _","userId":"05305253849747166776"}},"outputId":"ba5fe67f-b51c-43b7-b99e-c8276bb3cda7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting utils\n","  Downloading utils-1.0.2.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: utils\n","  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13905 sha256=8e52bbccfa254b69d3c6dc9ecbe9ef260c4e4e4822321be9291a24a5e7282831\n","  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n","Successfully built utils\n","Installing collected packages: utils\n","Successfully installed utils-1.0.2\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pNlIL_T7AZ8t","executionInfo":{"status":"ok","timestamp":1709949077479,"user_tz":-480,"elapsed":296,"user":{"displayName":"CHIANG KHENG HE _","userId":"05305253849747166776"}}},"outputs":[],"source":["import os\n","import torch\n","import pandas as pd\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","\n","from sklearn import model_selection\n","from sklearn import metrics\n","import transformers\n","import tokenizers\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm.autonotebook import tqdm\n","import utils"]},{"cell_type":"code","source":["df = pd.read_excel('/content/cleaned_data(trim30wOpen_v3).xlsx')\n","df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AygFW4PsFVvz","executionInfo":{"status":"ok","timestamp":1709952306359,"user_tz":-480,"elapsed":1906,"user":{"displayName":"CHIANG KHENG HE _","userId":"05305253849747166776"}},"outputId":"1274f957-5d00-4813-b922-55b5ded07eb3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['have you had a mental health disorder in the past? (I Don't Know=0, No=1, Yes=2)',\n","       'have you ever sought treatment for a mental health disorder from a mental health professional?',\n","       'do you have a family history of mental illness? (I Don't Know=0, No=1, Yes=2)',\n","       'did your previous employers provide resources to learn more about mental health disorders and how to seek help? (I Don't Know=0, No=1, Some=2, Yes=3)',\n","       'what country do you work in? (Afghanistan=0, Albania=1, Angola=2, Argentina=3, Armenia=4, Australia=5, Austria=6, Bangladesh=7, Belarus=8, Belgium=9, Botswana=10, Brazil=11, Bulgaria=12, Cameroon=13, Canada=14, China=15, Colombia=16, Croatia=17, Czech Republic=18, Denmark=19, Eritrea=20, Estonia=21, Ethiopia=22, Finland=23, France=24, Germany=25, Greece=26, Hong Kong=27, Hungary=28, Iceland=29, India=30, Indonesia=31, Ireland=32, Israel=33, Italy=34, Japan=35, Jordan=36, Kazakhstan=37, Kenya=38, Latvia=39, Luxembourg=40, Macedonia=41, Mauritius=42, Mexico=43, Missing=44, Mongolia=45, Netherlands=46, New Zealand=47, Nigeria=48, Norway=49, Other=50, Pakistan=51, Panama=52, Peru=53, Philippines=54, Poland=55, Portugal=56, Romania=57, Russia=58, Saudi Arabia=59, Serbia=60, Singapore=61, Slovenia=62, South Africa=63, Spain=64, Sri Lanka=65, Swaziland=66, Sweden=67, Switzerland=68, Taiwan=69, Turkey=70, Ukraine=71, United Kingdom=72, United States of America=73, Uruguay=74)',\n","       'have you ever discussed your mental health with your employer?',\n","       'have you ever discussed your mental health with coworkers?',\n","       'would you have felt more comfortable talking to your previous employer about your physical health or your mental health? (Mental health=0, None=1, Physical health=2, Same level of comfort for each=3)',\n","       'did you ever discuss your mental health with a previous coworker(s)?',\n","       'are you openly identified at work as a person with a mental health issue?',\n","       'overall, how well do you think the tech industry supports employees with mental health issues?',\n","       'did you ever have a previous coworker discuss their or another coworker's mental health with you?',\n","       'overall, how much importance did your previous employer place on physical health?',\n","       'have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace? (Maybe=0, No=1, Yes=2)',\n","       'does your employer offer resources to learn more about mental health disorders and options for seeking help? (I Don't Know=0, No=1, Yes=2)',\n","       'were you aware of the options for mental health care provided by your previous employers? (Aware=0, Not Aware=1)',\n","       'would you bring up your mental health with a potential employer in an interview? (Maybe=0, No=1, Yes=2)',\n","       'have your previous employers provided mental health benefits? (I Don't Know=0, No=1, Some=2, Yes=3)',\n","       'if a mental health issue prompted you to request a medical leave from work, how easy or difficult would it be to ask for that leave? (Difficult=0, I Don't Know=1, Neither easy nor difficult=2, Somewhat difficult=3, Somewhat easy=4, Very easy=5)',\n","       'have your observations of how another individual who discussed a mental health issue made you less likely to reveal a mental health issue yourself in your current workplace? (Maybe=0, No=1, Yes=2)',\n","       'why or why not?', 'why or why not?_dominant_topic',\n","       'why or why not?_encoded_compound',\n","       'is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer? (I Don't Know=0, No=1, Yes=2)',\n","       'would you feel comfortable discussing a mental health issue with your coworkers? (Maybe=0, No=1, Yes=2)',\n","       'briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.',\n","       'briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees._dominant_topic',\n","       'briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees._encoded_compound',\n","       'what is your race? (American Indian or Alaska Native=0, Asian=1, Black or African American=2, Caucasian=3, European American=4, Hispanic=5, I prefer not to answer=6, Missing=7, More than one of the above=8, White=9, White Hispanic=10)',\n","       'did you ever discuss your mental health with your previous employer?',\n","       'what is your age? (0=0, 1=1, 11=2, 18=3, 19=4, 2=5, 20=6, 21=7, 22=8, 223=9, 23=10, 24=11, 25=12, 26=13, 27=14, 28=15, 29=16, 30=17, 31=18, 32=19, 33=20, 34=21, 35=22, 36=23, 37=24, 38=25, 39=26, 40=27, 41=28, 42=29, 43=30, 44=31, 45=32, 46=33, 47=34, 48=35, 49=36, 5=37, 50=38, 51=39, 52=40, 53=41, 54=42, 55=43, 56=44, 57=45, 58=46, 59=47, 60=48, 61=49, 62=50, 63=51, 64=52, 65=53, 66=54, 67=55, 76=56, Missing=57)',\n","       'why or why not?.1', 'why or why not?.1_dominant_topic',\n","       'why or why not?.1_encoded_compound',\n","       'what is your gender? (1=0, 2=1, 3=2, Missing=3)'],\n","      dtype='object')"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFdc0R6lAZ8u"},"outputs":[],"source":["ROBERTA_PATH = \"../input/roberta-base\"\n","TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n","    vocab_file=f\"{ROBERTA_PATH}/vocab.json\",\n","    merges_file=f\"{ROBERTA_PATH}/merges.txt\",\n","    lowercase=True,\n","    add_prefix_space=True\n",")\n","TRAINING_FILE = \"../input/tweet-train-folds/train_folds.csv\"\n","MAX_LEN = 192\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 8\n","EPOCHS = 5"]},{"cell_type":"markdown","metadata":{"id":"BmooVhkiAZ8u"},"source":["# Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"0CEup4swAZ8u"},"outputs":[],"source":["def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n","    \"\"\"\n","    Processes the tweet and outputs the features necessary for model training and inference.\n","\n","    Note: there are some differences between this and the RoERTa version (roberta-base), mostly due to differences in token codes and special tokens\n","    \"\"\"\n","    tweet = \" \" + \" \".join(str(tweet).split())\n","    selected_text = \" \" + \" \".join(str(selected_text).split())\n","\n","    len_st = len(selected_text) - 1\n","    idx0 = None\n","    idx1 = None\n","\n","    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n","        if \" \" + tweet[ind: ind+len_st] == selected_text:\n","            idx0 = ind\n","            idx1 = ind + len_st - 1\n","            break\n","\n","    char_targets = [0] * len(tweet)\n","    if idx0 != None and idx1 != None:\n","        for ct in range(idx0, idx1 + 1):\n","            char_targets[ct] = 1\n","\n","    tok_tweet = tokenizer.encode(tweet)\n","    input_ids_orig = tok_tweet.ids\n","    tweet_offsets = tok_tweet.offsets\n","\n","    target_idx = []\n","    for j, (offset1, offset2) in enumerate(tweet_offsets):\n","        if sum(char_targets[offset1: offset2]) > 0:\n","            target_idx.append(j)\n","\n","    targets_start = target_idx[0]\n","    targets_end = target_idx[-1]\n","\n","    sentiment_id = {\n","        'positive': 1313,\n","        'negative': 2430,\n","        'neutral': 7974\n","    }\n","\n","    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n","    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n","    mask = [1] * len(token_type_ids)\n","    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n","    targets_start += 4\n","    targets_end += 4\n","\n","    padding_length = max_len - len(input_ids)\n","    if padding_length > 0:\n","        input_ids = input_ids + ([1] * padding_length)\n","        mask = mask + ([0] * padding_length)\n","        token_type_ids = token_type_ids + ([0] * padding_length)\n","        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n","\n","    return {\n","        'ids': input_ids,\n","        'mask': mask,\n","        'token_type_ids': token_type_ids,\n","        'targets_start': targets_start,\n","        'targets_end': targets_end,\n","        'orig_tweet': tweet,\n","        'orig_selected': selected_text,\n","        'sentiment': sentiment,\n","        'offsets': tweet_offsets\n","    }"]},{"cell_type":"markdown","metadata":{"id":"ER-4Km2BAZ8v"},"source":["# Data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dMu7L1FAZ8v"},"outputs":[],"source":["class TweetDataset:\n","    \"\"\"\n","    Dataset which stores the tweets and returns them as processed features\n","    \"\"\"\n","    def __init__(self, tweet, sentiment, selected_text):\n","        self.tweet = tweet\n","        self.sentiment = sentiment\n","        self.selected_text = selected_text\n","        self.tokenizer = TOKENIZER\n","        self.max_len = MAX_LEN\n","\n","    def __len__(self):\n","        return len(self.tweet)\n","\n","    def __getitem__(self, item):\n","        data = process_data(\n","            self.tweet[item],\n","            self.selected_text[item],\n","            self.sentiment[item],\n","            self.tokenizer,\n","            self.max_len\n","        )\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        return {\n","            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n","            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n","            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n","            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n","            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n","            'orig_tweet': data[\"orig_tweet\"],\n","            'orig_selected': data[\"orig_selected\"],\n","            'sentiment': data[\"sentiment\"],\n","            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n","        }"]},{"cell_type":"markdown","metadata":{"id":"g6U5GbYGAZ8v"},"source":["# The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"ir6Jn5ryAZ8v"},"outputs":[],"source":["class TweetModel(transformers.BertPreTrainedModel):\n","    \"\"\"\n","    Model class that combines a pretrained bert model with a linear later\n","    \"\"\"\n","    def __init__(self, conf):\n","        super(TweetModel, self).__init__(conf)\n","        # Load the pretrained RobBERTa model\n","        self.roberta = transformers.RobertaModel.from_pretrained(ROBERTA_PATH, config=conf)\n","        # Set 10% dropout to be applied to the RobBERTa backbone's output\n","        self.drop_out = nn.Dropout(0.1)\n","        # 768 is the dimensionality of roberta-base's hidden representations\n","        # Multiplied by 2 since the forward pass concatenates the last two hidden representation layers\n","        # The output will have two dimensions (\"start_logits\", and \"end_logits\")\n","        self.l0 = nn.Linear(768 * 2, 2)\n","        torch.nn.init.normal_(self.l0.weight, std=0.02)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # Return the hidden states from the BERT backbone\n","        _, _, out = self.roberta(\n","            ids,\n","            attention_mask=mask,\n","            token_type_ids=token_type_ids\n","        ) # bert_layers x bs x SL x (768 * 2)\n","\n","        # Concatenate the last two hidden states\n","        # This is done since experiments have shown that just getting the last layer\n","        # gives out vectors that may be too taylored to the original RoBERTa training objectives (MLM + NSP)\n","        # Sample explanation: https://bert-as-service.readthedocs.io/en/latest/section/faq.html#why-not-the-last-hidden-layer-why-second-to-last\n","        out = torch.cat((out[-1], out[-2]), dim=-1) # bs x SL x (768 * 2)\n","        # Apply 10% dropout to the last 2 hidden states\n","        out = self.drop_out(out) # bs x SL x (768 * 2)\n","        # The \"dropped out\" hidden vectors are now fed into the linear layer to output two scores\n","        logits = self.l0(out) # bs x SL x 2\n","\n","        # Splits the tensor into start_logits and end_logits\n","        # (bs x SL x 2) -> (bs x SL x 1), (bs x SL x 1)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","\n","        start_logits = start_logits.squeeze(-1) # (bs x SL)\n","        end_logits = end_logits.squeeze(-1) # (bs x SL)\n","\n","        return start_logits, end_logits"]},{"cell_type":"markdown","metadata":{"id":"73-2alYMAZ8v"},"source":["# Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2VRjjJjAZ8v"},"outputs":[],"source":["def loss_fn(start_logits, end_logits, start_positions, end_positions):\n","    \"\"\"\n","    Return the sum of the cross entropy losses for both the start and end logits\n","    \"\"\"\n","    loss_fct = nn.CrossEntropyLoss()\n","    start_loss = loss_fct(start_logits, start_positions)\n","    end_loss = loss_fct(end_logits, end_positions)\n","    total_loss = (start_loss + end_loss)\n","    return total_loss"]},{"cell_type":"markdown","metadata":{"id":"4h8dkxUzAZ8w"},"source":["# Training Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YhRPKc3AZ8w"},"outputs":[],"source":["def train_fn(data_loader, model, optimizer, device, scheduler=None):\n","    \"\"\"\n","    Trains the bert model on the twitter data\n","    \"\"\"\n","    # Set model to training mode (dropout + sampled batch norm is activated)\n","    model.train()\n","    losses = utils.AverageMeter()\n","    jaccards = utils.AverageMeter()\n","\n","    # Set tqdm to add loading screen and set the length\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","\n","    # Train the model on each batch\n","    for bi, d in enumerate(tk0):\n","\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        targets_start = d[\"targets_start\"]\n","        targets_end = d[\"targets_end\"]\n","        sentiment = d[\"sentiment\"]\n","        orig_selected = d[\"orig_selected\"]\n","        orig_tweet = d[\"orig_tweet\"]\n","        targets_start = d[\"targets_start\"]\n","        targets_end = d[\"targets_end\"]\n","        offsets = d[\"offsets\"]\n","\n","\n","        # Move ids, masks, and targets to gpu while setting as torch.long\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets_start = targets_start.to(device, dtype=torch.long)\n","        targets_end = targets_end.to(device, dtype=torch.long)\n","\n","        # Reset gradients\n","        model.zero_grad()\n","        # Use ids, masks, and token types as input to the model\n","        # Predict logits for each of the input tokens for each batch\n","        outputs_start, outputs_end = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids,\n","        ) # (bs x SL), (bs x SL)\n","        # Calculate batch loss based on CrossEntropy\n","        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n","        # Calculate gradients based on loss\n","        loss.backward()\n","        # Adjust weights based on calculated gradients\n","        optimizer.step()\n","        # Update scheduler\n","        scheduler.step()\n","\n","        # Apply softmax to the start and end logits\n","        # This squeezes each of the logits in a sequence to a value between 0 and 1, while ensuring that they sum to 1\n","        # This is similar to the characteristics of \"probabilities\"\n","        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","\n","        # Calculate the jaccard score based on the predictions for this batch\n","        jaccard_scores = []\n","        for px, tweet in enumerate(orig_tweet):\n","            selected_tweet = orig_selected[px]\n","            tweet_sentiment = sentiment[px]\n","            jaccard_score, _ = calculate_jaccard_score(\n","                original_tweet=tweet, # Full text of the px'th tweet in the batch\n","                target_string=selected_tweet, # Span containing the specified sentiment for the px'th tweet in the batch\n","                sentiment_val=tweet_sentiment, # Sentiment of the px'th tweet in the batch\n","                idx_start=np.argmax(outputs_start[px, :]), # Predicted start index for the px'th tweet in the batch\n","                idx_end=np.argmax(outputs_end[px, :]), # Predicted end index for the px'th tweet in the batch\n","                offsets=offsets[px] # Offsets for each of the tokens for the px'th tweet in the batch\n","            )\n","            jaccard_scores.append(jaccard_score)\n","        # Update the jaccard score and loss\n","        # For details, refer to `AverageMeter` in https://www.kaggle.com/abhishek/utils\n","        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","        losses.update(loss.item(), ids.size(0))\n","        # Print the average loss and jaccard score at the end of each batch\n","        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"]},{"cell_type":"markdown","metadata":{"id":"tpXQU6nwAZ8w"},"source":["# Evaluation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAWZmNRKAZ8w"},"outputs":[],"source":["def calculate_jaccard_score(\n","    original_tweet,\n","    target_string,\n","    sentiment_val,\n","    idx_start,\n","    idx_end,\n","    offsets,\n","    verbose=False):\n","    \"\"\"\n","    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets\n","    \"\"\"\n","\n","    # A span's start index has to be greater than or equal to the end index\n","    # If this doesn't hold, the start index is set to equal the end index (the span is a single token)\n","    if idx_end < idx_start:\n","        idx_end = idx_start\n","\n","    # Combine into a string the tokens that belong to the predicted span\n","    filtered_output  = \"\"\n","    for ix in range(idx_start, idx_end + 1):\n","        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n","        # If the token is not the last token in the tweet, and the ending offset of the current token is less\n","        # than the beginning offset of the following token, add a space.\n","        # Basically, add a space when the next token (word piece) corresponds to a new word\n","        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n","            filtered_output += \" \"\n","\n","    # Set the predicted output as the original tweet when the tweet's sentiment is \"neutral\", or the tweet only contains one word\n","    if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n","        filtered_output = original_tweet\n","\n","    # Calculate the jaccard score between the predicted span, and the actual span\n","    # The IOU (intersection over union) approach is detailed in the utils module's `jaccard` function:\n","    # https://www.kaggle.com/abhishek/utils\n","    jac = utils.jaccard(target_string.strip(), filtered_output.strip())\n","    return jac, filtered_output\n","\n","\n","def eval_fn(data_loader, model, device):\n","    \"\"\"\n","    Evaluation function to predict on the test set\n","    \"\"\"\n","    # Set model to evaluation mode\n","    # I.e., turn off dropout and set batchnorm to use overall mean and variance (from training), rather than batch level mean and variance\n","    # Reference: https://github.com/pytorch/pytorch/issues/5406\n","    model.eval()\n","    losses = utils.AverageMeter()\n","    jaccards = utils.AverageMeter()\n","\n","    # Turns off gradient calculations (https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch)\n","    with torch.no_grad():\n","        tk0 = tqdm(data_loader, total=len(data_loader))\n","        # Make predictions and calculate loss / jaccard score for each batch\n","        for bi, d in enumerate(tk0):\n","            ids = d[\"ids\"]\n","            token_type_ids = d[\"token_type_ids\"]\n","            mask = d[\"mask\"]\n","            sentiment = d[\"sentiment\"]\n","            orig_selected = d[\"orig_selected\"]\n","            orig_tweet = d[\"orig_tweet\"]\n","            targets_start = d[\"targets_start\"]\n","            targets_end = d[\"targets_end\"]\n","            offsets = d[\"offsets\"].numpy()\n","\n","            # Move ids, masks, and targets to gpu while setting as torch.long\n","            ids = ids.to(device, dtype=torch.long)\n","            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets_start = targets_start.to(device, dtype=torch.long)\n","            targets_end = targets_end.to(device, dtype=torch.long)\n","\n","            # Move tensors to GPU for faster matrix calculations\n","            ids = ids.to(device, dtype=torch.long)\n","            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets_start = targets_start.to(device, dtype=torch.long)\n","            targets_end = targets_end.to(device, dtype=torch.long)\n","\n","            # Predict logits for start and end indexes\n","            outputs_start, outputs_end = model(\n","                ids=ids,\n","                mask=mask,\n","                token_type_ids=token_type_ids\n","            )\n","            # Calculate loss for the batch\n","            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n","            # Apply softmax to the predicted logits for the start and end indexes\n","            # This converts the \"logits\" to \"probability-like\" scores\n","            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","            # Calculate jaccard scores for each tweet in the batch\n","            jaccard_scores = []\n","            for px, tweet in enumerate(orig_tweet):\n","                selected_tweet = orig_selected[px]\n","                tweet_sentiment = sentiment[px]\n","                jaccard_score, _ = calculate_jaccard_score(\n","                    original_tweet=tweet,\n","                    target_string=selected_tweet,\n","                    sentiment_val=tweet_sentiment,\n","                    idx_start=np.argmax(outputs_start[px, :]),\n","                    idx_end=np.argmax(outputs_end[px, :]),\n","                    offsets=offsets[px]\n","                )\n","                jaccard_scores.append(jaccard_score)\n","\n","            # Update running jaccard score and loss\n","            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","            losses.update(loss.item(), ids.size(0))\n","            # Print the running average loss and jaccard score\n","            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n","\n","    print(f\"Jaccard = {jaccards.avg}\")\n","    return jaccards.avg"]},{"cell_type":"markdown","metadata":{"id":"LL43gTw4AZ8w"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AIJ4pV9AZ8w"},"outputs":[],"source":["def run(fold):\n","    \"\"\"\n","    Train model for a speciied fold\n","    \"\"\"\n","    # Read training csv\n","    dfx = pd.read_csv(TRAINING_FILE)\n","\n","    # Set train validation set split\n","    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n","    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n","\n","    # Instantiate TweetDataset with training data\n","    train_dataset = TweetDataset(\n","        tweet=df_train.text.values,\n","        sentiment=df_train.sentiment.values,\n","        selected_text=df_train.selected_text.values\n","    )\n","\n","    # Instantiate DataLoader with `train_dataset`\n","    # This is a generator that yields the dataset in batches\n","    train_data_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=TRAIN_BATCH_SIZE,\n","        num_workers=4\n","    )\n","\n","    # Instantiate TweetDataset with validation data\n","    valid_dataset = TweetDataset(\n","        tweet=df_valid.text.values,\n","        sentiment=df_valid.sentiment.values,\n","        selected_text=df_valid.selected_text.values\n","    )\n","\n","    # Instantiate DataLoader with `valid_dataset`\n","    valid_data_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size=VALID_BATCH_SIZE,\n","        num_workers=2\n","    )\n","\n","    # Set device as `cuda` (GPU)\n","    device = torch.device(\"cuda\")\n","    # Load pretrained RoBERTa\n","    model_config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH)\n","    # Output hidden states\n","    # This is important to set since we want to concatenate the hidden states from the last 2 BERT layers\n","    model_config.output_hidden_states = True\n","    # Instantiate our model with `model_config`\n","    model = TweetModel(conf=model_config)\n","    # Move the model to the GPU\n","    model.to(device)\n","\n","    # Calculate the number of training steps\n","    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n","    # Get the list of named parameters\n","    param_optimizer = list(model.named_parameters())\n","    # Specify parameters where weight decay shouldn't be applied\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    # Define two sets of parameters: those with weight decay, and those without\n","    optimizer_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","    ]\n","    # Instantiate AdamW optimizer with our two sets of parameters, and a learning rate of 3e-5\n","    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n","    # Create a scheduler to set the learning rate at each training step\n","    # \"Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period.\" (https://pytorch.org/docs/stable/optim.html)\n","    # Since num_warmup_steps = 0, the learning rate starts at 3e-5, and then linearly decreases at each training step\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimiz\n","        num_warmup_steps=0,\n","        num_training_steps=num_train_steps\n","    )\n","\n","    # Apply early stopping with patience of 2\n","    # This means to stop training new epochs when 2 rounds have passed without any improvement\n","    es = utils.EarlyStopping(patience=2, mode=\"max\")\n","    print(f\"Training is Starting for fold={fold}\")\n","\n","    # I'm training only for 3 epochs even though I specified 5!!!\n","    for epoch in range(3):\n","        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n","        jaccard = eval_fn(valid_data_loader, model, device)\n","        print(f\"Jaccard Score = {jaccard}\")\n","        es(jaccard, model, model_path=f\"model_{fold}.bin\")\n","        if es.early_stop:\n","            print(\"Early stopping\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8p5ibI5FAZ8x"},"outputs":[],"source":["fold=0\n","# Read training csv\n","dfx = pd.read_csv(TRAINING_FILE)\n","\n","# Set train validation set split\n","df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n","df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n","\n","# Instantiate TweetDataset with training data\n","train_dataset = TweetDataset(\n","    tweet=df_train.text.values,\n","    sentiment=df_train.sentiment.values,\n","    selected_text=df_train.selected_text.values\n",")\n","\n","# Instantiate DataLoader with `train_dataset`\n","# This is a generator that yields the dataset in batches\n","train_data_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    num_workers=4\n",")\n","\n","# Instantiate TweetDataset with validation data\n","valid_dataset = TweetDataset(\n","    tweet=df_valid.text.values,\n","    sentiment=df_valid.sentiment.values,\n","    selected_text=df_valid.selected_text.values\n",")\n","\n","# Instantiate DataLoader with `valid_dataset`\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=VALID_BATCH_SIZE,\n","    num_workers=2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"referenced_widgets":["24c7e0b24a434f72b69e68f6705f66bc","4dffe3d88a084383bf440d86d32b7e4a","498df6e1b3f44cb195e0c10d4ac03ce2","e0ecb7c1c1ea431da84f16b4de8c2250","62eaff26e51f429296876810f9b614c3","c519bb122c844045862a52ad359a5e26"]},"id":"eZo9vjHtAZ8x","outputId":"42b3169f-1d17-4fec-c2e2-bfb8fe362135"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training is Starting for fold=0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24c7e0b24a434f72b69e68f6705f66bc","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dffe3d88a084383bf440d86d32b7e4a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6933192892345158\n","Jaccard Score = 0.6933192892345158\n","Validation score improved (-inf --> 0.6933192892345158). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"498df6e1b3f44cb195e0c10d4ac03ce2","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0ecb7c1c1ea431da84f16b4de8c2250","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.695823917921098\n","Jaccard Score = 0.695823917921098\n","Validation score improved (0.6933192892345158 --> 0.695823917921098). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62eaff26e51f429296876810f9b614c3","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c519bb122c844045862a52ad359a5e26","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7012654659253472\n","Jaccard Score = 0.7012654659253472\n","Validation score improved (0.695823917921098 --> 0.7012654659253472). Saving model!\n"]}],"source":["\n","run(fold=0)"]},{"cell_type":"markdown","metadata":{"id":"0GUJX_TJAZ8y"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"referenced_widgets":["379e22123df5496bae5ca9e6a0a7f5c4","8750594f72cf487292ab5f3b0879a3df","f02a6549902e47dd82856504c9d210f3","ddc6fe69cc124366bad0d597ff8f64bd","bc84700dac4a472eb8d2ab907bfc2c96","3bba8815435e47ba8195beb8773c038e"]},"id":"39ixQ_xGAZ8y","outputId":"9c977263-47bf-4f2d-ea30-d9b22f666fa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training is Starting for fold=1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"379e22123df5496bae5ca9e6a0a7f5c4","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8750594f72cf487292ab5f3b0879a3df","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6924868723749917\n","Jaccard Score = 0.6924868723749917\n","Validation score improved (-inf --> 0.6924868723749917). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f02a6549902e47dd82856504c9d210f3","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddc6fe69cc124366bad0d597ff8f64bd","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6946728183933234\n","Jaccard Score = 0.6946728183933234\n","Validation score improved (0.6924868723749917 --> 0.6946728183933234). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc84700dac4a472eb8d2ab907bfc2c96","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bba8815435e47ba8195beb8773c038e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6963758899726998\n","Jaccard Score = 0.6963758899726998\n","Validation score improved (0.6946728183933234 --> 0.6963758899726998). Saving model!\n"]}],"source":["run(fold=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"referenced_widgets":["2248cffa9b004b2d921d19070cf86f8a","7b0f875f9def45d898e6eea957719687","8d907d8931734d379dcbbac5a4d1e789","5ccd83b81e0b4d198b6b15bf3772a33c","2cb487eca7054a1b805c8b3466f7f585","da9c1b18088d4b47b8f24902395410ae"]},"id":"UK4rTag-AZ8y","outputId":"188c1c7c-af9d-4528-95d6-1cb586cd5e42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training is Starting for fold=2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2248cffa9b004b2d921d19070cf86f8a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b0f875f9def45d898e6eea957719687","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6948432997714371\n","Jaccard Score = 0.6948432997714371\n","Validation score improved (-inf --> 0.6948432997714371). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d907d8931734d379dcbbac5a4d1e789","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ccd83b81e0b4d198b6b15bf3772a33c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7060917269105861\n","Jaccard Score = 0.7060917269105861\n","Validation score improved (0.6948432997714371 --> 0.7060917269105861). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cb487eca7054a1b805c8b3466f7f585","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da9c1b18088d4b47b8f24902395410ae","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7068711063073332\n","Jaccard Score = 0.7068711063073332\n","EarlyStopping counter: 1 out of 2\n"]}],"source":["run(fold=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"referenced_widgets":["3167f205c5994f8e983e04596b74ea6e","d04b74c9428e48c8a8a011d6d4a6076f","c0b20f18f42c49c2ba7059fd5724a180","13ffd23a49924efe8a63e266b607311b","b8a88e060b8f4b248088785df53af71c","c3648cac08b648e78db858a9af66dbfe"]},"id":"GbMRSRDLAZ8y","outputId":"d0ed6b71-653a-44ae-860e-e9a49c865ca5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training is Starting for fold=3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3167f205c5994f8e983e04596b74ea6e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d04b74c9428e48c8a8a011d6d4a6076f","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6992004215628471\n","Jaccard Score = 0.6992004215628471\n","Validation score improved (-inf --> 0.6992004215628471). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0b20f18f42c49c2ba7059fd5724a180","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13ffd23a49924efe8a63e266b607311b","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7031322177285821\n","Jaccard Score = 0.7031322177285821\n","Validation score improved (0.6992004215628471 --> 0.7031322177285821). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8a88e060b8f4b248088785df53af71c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3648cac08b648e78db858a9af66dbfe","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7033698508264047\n","Jaccard Score = 0.7033698508264047\n","EarlyStopping counter: 1 out of 2\n"]}],"source":["run(fold=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"referenced_widgets":["0c3ac25cc3194e989f4af5b0a34642bc","c222f039a9a1480ab6c0125fd7c82216","7fa880128dff4c2cbc4e8f32fb594124","b4ca03ce9b88432db022f26452bf3683","855fe947b56041c68991053addac54d9","f2e8fe24a69246fca25098b4fd518f83"]},"id":"sIaweHUfAZ8y","outputId":"687b83d3-f5bc-45b8-ec73-2adf683ebc77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training is Starting for fold=4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c3ac25cc3194e989f4af5b0a34642bc","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c222f039a9a1480ab6c0125fd7c82216","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.6987707893178341\n","Jaccard Score = 0.6987707893178341\n","Validation score improved (-inf --> 0.6987707893178341). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fa880128dff4c2cbc4e8f32fb594124","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4ca03ce9b88432db022f26452bf3683","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7069171344913878\n","Jaccard Score = 0.7069171344913878\n","Validation score improved (0.6987707893178341 --> 0.7069171344913878). Saving model!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"855fe947b56041c68991053addac54d9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2e8fe24a69246fca25098b4fd518f83","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Jaccard = 0.7102376668583217\n","Jaccard Score = 0.7102376668583217\n","Validation score improved (0.7069171344913878 --> 0.7102376668583217). Saving model!\n"]}],"source":["run(fold=4)"]},{"cell_type":"markdown","metadata":{"id":"mBHtvBGEAZ8z"},"source":["# Do the evaluation on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiXOHGT-AZ8z"},"outputs":[],"source":["df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n","df_test.loc[:, \"selected_text\"] = df_test.text.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1ClGYcIAZ8z"},"outputs":[],"source":["device = torch.device(\"cuda\")\n","model_config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH)\n","model_config.output_hidden_states = True"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"id":"T-EAPeMBAZ8z","outputId":"528c858f-e5d8-424a-e1be-6182f5d486c1"},"outputs":[{"data":{"text/plain":["TweetModel(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (drop_out): Dropout(p=0.1, inplace=False)\n","  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Load each of the five trained models and move to GPU\n","model1 = TweetModel(conf=model_config)\n","model1.to(device)\n","model1.load_state_dict(torch.load(\"model_0.bin\"))\n","model1.eval()\n","\n","model2 = TweetModel(conf=model_config)\n","model2.to(device)\n","model2.load_state_dict(torch.load(\"model_1.bin\"))\n","model2.eval()\n","\n","model3 = TweetModel(conf=model_config)\n","model3.to(device)\n","model3.load_state_dict(torch.load(\"model_2.bin\"))\n","model3.eval()\n","\n","model4 = TweetModel(conf=model_config)\n","model4.to(device)\n","model4.load_state_dict(torch.load(\"model_3.bin\"))\n","model4.eval()\n","\n","model5 = TweetModel(conf=model_config)\n","model5.to(device)\n","model5.load_state_dict(torch.load(\"model_4.bin\"))\n","model5.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["7bc28d8528314b349807e6f8968b8ee1"]},"id":"32fh3zAcAZ8z","outputId":"5bb53b3d-aa8d-4a7f-e06b-5024a8a687ce"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bc28d8528314b349807e6f8968b8ee1","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=442.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["final_output = []\n","\n","# Instantiate TweetDataset with the test data\n","test_dataset = TweetDataset(\n","        tweet=df_test.text.values,\n","        sentiment=df_test.sentiment.values,\n","        selected_text=df_test.selected_text.values\n",")\n","\n","# Instantiate DataLoader with `test_dataset`\n","data_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    shuffle=False,\n","    batch_size=VALID_BATCH_SIZE,\n","    num_workers=1\n",")\n","\n","# Turn of gradient calculations\n","with torch.no_grad():\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    # Predict the span containing the sentiment for each batch\n","    for bi, d in enumerate(tk0):\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        sentiment = d[\"sentiment\"]\n","        orig_selected = d[\"orig_selected\"]\n","        orig_tweet = d[\"orig_tweet\"]\n","        targets_start = d[\"targets_start\"]\n","        targets_end = d[\"targets_end\"]\n","        offsets = d[\"offsets\"].numpy()\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets_start = targets_start.to(device, dtype=torch.long)\n","        targets_end = targets_end.to(device, dtype=torch.long)\n","\n","        # Predict start and end logits for each of the five models\n","        outputs_start1, outputs_end1 = model1(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_start2, outputs_end2 = model2(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_start3, outputs_end3 = model3(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_start4, outputs_end4 = model4(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_start5, outputs_end5 = model5(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        # Get the average start and end logits across the five models and use these as predictions\n","        # This is a form of \"ensembling\"\n","        outputs_start = (\n","            outputs_start1\n","            + outputs_start2\n","            + outputs_start3\n","            + outputs_start4\n","            + outputs_start5\n","        ) / 5\n","        outputs_end = (\n","            outputs_end1\n","            + outputs_end2\n","            + outputs_end3\n","            + outputs_end4\n","            + outputs_end5\n","        ) / 5\n","\n","        # Apply softmax to the predicted start and end logits\n","        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","\n","        # Convert the start and end scores to actual predicted spans (in string form)\n","        for px, tweet in enumerate(orig_tweet):\n","            selected_tweet = orig_selected[px]\n","            tweet_sentiment = sentiment[px]\n","            _, output_sentence = calculate_jaccard_score(\n","                original_tweet=tweet,\n","                target_string=selected_tweet,\n","                sentiment_val=tweet_sentiment,\n","                idx_start=np.argmax(outputs_start[px, :]),\n","                idx_end=np.argmax(outputs_end[px, :]),\n","                offsets=offsets[px]\n","            )\n","            final_output.append(output_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0R4yLhUMAZ8z"},"outputs":[],"source":["# post-process trick:\n","# Note: This trick comes from: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/140942\n","# When the LB resets, this trick won't help\n","def post_process(selected):\n","    return \" \".join(set(selected.lower().split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6al59dGAZ8z"},"outputs":[],"source":["sample = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\n","sample.loc[:, 'selected_text'] = final_output\n","sample.selected_text = sample.selected_text.map(post_process)\n","sample.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynJF5tBaAZ8z","outputId":"e42f7b88-1161-41c5-8f8a-ab8d9e7e48d1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>selected_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>last day of session http://twitpic.com/67ezh the</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>exciting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eee518ae67</td>\n","      <td>shame! a such</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01082688c6</td>\n","      <td>bday! happy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33987a8ee5</td>\n","      <td>i like it!!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                     selected_text\n","0  f87dea47db  last day of session http://twitpic.com/67ezh the\n","1  96d74cb729                                          exciting\n","2  eee518ae67                                     shame! a such\n","3  01082688c6                                       bday! happy\n","4  33987a8ee5                                       i like it!!"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["sample.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}